<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI/Human Text Detector Pipeline</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.x/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-vis"></script>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        .container { display: flex; flex-wrap: wrap; gap: 20px; }
        .section { border: 1px solid #ccc; padding: 15px; border-radius: 5px; flex: 1 1 300px; }
        h3 { border-bottom: 2px solid #eee; padding-bottom: 5px; }
        .status { margin-top: 10px; font-weight: bold; }
        #live-prediction-output { margin-top: 15px; padding: 10px; border-radius: 5px; min-height: 50px; }
        .human { background-color: #e6ffe6; color: green; }
        .ai { background-color: #ffe6e6; color: red; }
    </style>
</head>
<body>

    <h1>AI/Human Text Detection Pipeline (Client-Side)</h1>
    <div class="container">

        <div class="section" id="step1">
            <h3>1. DATA LOAD & PREPARATION</h3>
            <label>Train CSV:</label>
            <input type="file" id="trainFile" accept=".csv"><br><br>
            <label>Test CSV (for batch prediction):</label>
            <input type="file" id="testFile" accept=".csv"><br><br>
            <button onclick="loadAndPrepareData()">Load & Prepare Data</button>
            <div class="status" id="loadStatus">Awaiting File Upload...</div>
        </div>

        <div class="section" id="step3">
            <h3>3. PREPROCESSING & TOKENIZATION</h3>
            <label>Max Sequence Length:</label>
            <input type="number" id="maxLength" value="100" min="10">
            <label>Embedding Dimension:</label>
            <input type="number" id="embeddingDim" value="32" min="16"><br><br>
            <button onclick="preprocessAndTokenize()" disabled id="tokenizeBtn">Tokenize & Split</button>
            <div class="status" id="tokenizeStatus"></div>
        </div>

        <div class="section" id="step56">
            <h3>5 & 6. MODEL CONSTRUCTION & TRAINING</h3>
            <button onclick="trainModel()" disabled id="trainBtn">Build & Train Model</button>
            <div class="status" id="trainStatus"></div>
        </div>

        <div class="section" id="step7">
            <h3>7. LIVE PREDICTION INTERFACE</h3>
            <textarea id="liveTextInput" rows="5" cols="40" placeholder="Paste text here to predict (Human or AI)..."></textarea><br>
            <button onclick="livePredict()" disabled id="predictBtn">Predict</button>
            <div id="live-prediction-output"></div>
        </div>

        <div class="section" id="step89">
            <h3>8 & 9. EVALUATION & BATCH EXPORT</h3>
            <button onclick="evaluateModel()" disabled id="evaluateBtn">Evaluate Model (Metrics)</button><br><br>
            <button onclick="batchPredictAndExport()" disabled id="batchBtn">Batch Predict & Export CSV</button>
            <div class="status" id="exportStatus"></div>
        </div>

    </div>
    
    <div id="vis-container"></div>
    <div id="metrics-output"></div>

    <script>
        // Global variables to hold data, model, and vocabulary
        let trainData, testData;
        let trainXs, trainYs, valXs, valYs, testXs;
        let wordIndex = {};
        let vocabSize = 0;
        let model;

        // --- STEP 1: DATA LOAD & PREPARATION ---
        async function loadAndPrepareData() {
            const trainFile = document.getElementById('trainFile').files[0];
            const testFile = document.getElementById('testFile').files[0];
            const loadStatus = document.getElementById('loadStatus');

            if (!trainFile || !testFile) {
                loadStatus.textContent = "Please upload both train.csv and test.csv.";
                return;
            }

            try {
                // Helper to read and parse CSV
                const parseCSV = (file) => new Promise((resolve, reject) => {
                    const reader = new FileReader();
                    reader.onload = (e) => {
                        const csvText = e.target.result;
                        // Simple cleaning: remove surrounding quotes and escaped characters
                        const lines = csvText.split('\n').filter(l => l.trim() !== '');
                        const header = lines[0].split(',').map(h => h.replace(/^"|"$/g, '').trim());
                        
                        // Find column indices
                        const textColIndex = header.indexOf('answer_text');
                        const labelColIndex = header.indexOf('label');

                        if (textColIndex === -1 || labelColIndex === -1) {
                            return reject("CSV must contain 'answer_text' and 'label' columns.");
                        }

                        const data = lines.slice(1).map(line => {
                            // Simple CSV parsing (works for the provided sample structure)
                            const parts = line.split(/,(?=(?:(?:[^"]*"){2})*[^"]*$)/); // Split by comma, ignore commas inside quotes
                            if (parts.length < 3) return null; // Skip invalid lines

                            // Extract text and label, removing artifact quotes/newlines
                            let text = parts[textColIndex];
                            let label = parts[labelColIndex];
                            
                            // Basic cleaning (removing surrounding quotes and escaping)
                            text = text.replace(/^"|"$/g, '').replace(/\\n/g, ' ').replace(/\\r/g, ' ');
                            label = parseInt(label);

                            // Validate data format
                            if (!isNaN(label) && (label === 0 || label === 1) && text.length > 0) {
                                return { text: text, label: label };
                            }
                            return null;
                        }).filter(entry => entry !== null); // Filter out invalid entries

                        resolve(data);
                    };
                    reader.onerror = reject;
                    reader.readAsText(file);
                });

                loadStatus.textContent = "Processing data...";
                trainData = await parseCSV(trainFile);
                testData = await parseCSV(testFile);

                loadStatus.textContent = `✅ Data Loaded! Train samples: ${trainData.length}, Test samples: ${testData.length}.`;
                document.getElementById('tokenizeBtn').disabled = false;
                
                // --- STEP 2: DATA INSPECTION & ANALYSIS ---
                analyzeData(trainData);

            } catch (error) {
                loadStatus.textContent = `❌ Error loading data: ${error}`;
                console.error(error);
            } finally {
                // Ensure to clean up tensors if any were accidentally created (not strictly necessary here, but good practice)
                tf.tidy(() => {}); 
            }
        }

        // --- STEP 2: DATA INSPECTION & ANALYSIS (Visualization) ---
        function analyzeData(data) {
            const labels = data.map(d => d.label);
            const humanCount = labels.filter(l => l === 0).length;
            const aiCount = labels.filter(l => l === 1).length;
            const total = labels.length;

            const values = [
                { index: 'Human (0)', value: humanCount },
                { index: 'AI (1)', value: aiCount }
            ];

            const container = document.getElementById('vis-container');
            tfvis.render.barchart(
                container,
                values,
                {
                    title: `Class Balance (Total: ${total} samples)`,
                    height: 250,
                    fontSize: 14
                }
            );

            // Flag imbalanced datasets
            const imbalanceRatio = Math.min(humanCount, aiCount) / Math.max(humanCount, aiCount);
            if (imbalanceRatio < 0.5) {
                const flag = document.createElement('div');
                flag.textContent = "⚠️ Warning: Dataset is significantly imbalanced (ratio < 0.5).";
                flag.style.color = 'orange';
                container.appendChild(flag);
            }
        }

        // --- STEP 3: TEXT PREPROCESSING & TOKENIZATION ---
        function preprocessAndTokenize() {
            const maxLength = parseInt(document.getElementById('maxLength').value);
            const tokenizeStatus = document.getElementById('tokenizeStatus');

            if (!trainData || trainData.length === 0) {
                tokenizeStatus.textContent = "Please load data first.";
                return;
            }

            tokenizeStatus.textContent = "Building vocabulary and tokenizing...";

            // 1. Create vocabulary from training texts only
            const allTrainWords = trainData.flatMap(d => d.text.toLowerCase().split(/\W+/).filter(w => w.length > 0));
            const wordCounts = allTrainWords.reduce((acc, word) => {
                acc[word] = (acc[word] || 0) + 1;
                return acc;
            }, {});

            const sortedWords = Object.keys(wordCounts).sort((a, b) => wordCounts[b] - wordCounts[a]);
            
            // Start index from 2 (0 for padding, 1 for OOV/Unknown)
            wordIndex = {'<pad>': 0, '<unk>': 1};
            sortedWords.forEach((word, i) => {
                wordIndex[word] = i + 2;
            });
            vocabSize = Object.keys(wordIndex).length;

            // 2. Convert text to integer sequences and pad/truncate
            const textsToSequences = (data) => data.map(d => {
                const sequence = d.text.toLowerCase().split(/\W+/)
                    .filter(w => w.length > 0)
                    .map(word => wordIndex[word] || wordIndex['<unk>']);

                // Pad/truncate
                if (sequence.length > maxLength) {
                    return sequence.slice(0, maxLength); // Truncate
                } else if (sequence.length < maxLength) {
                    const padding = new Array(maxLength - sequence.length).fill(wordIndex['<pad>']);
                    return sequence.concat(padding); // Pad
                }
                return sequence;
            });
            
            const trainSequences = textsToSequences(trainData);
            const testSequences = textsToSequences(testData);

            // Convert labels to tensors (One-hot encoding for binary classification)
            const trainLabels = tf.tensor2d(trainData.map(d => [d.label]), [trainData.length, 1]);
            
            // 3. 80/20 train-validation split
            const trainSize = Math.floor(trainSequences.length * 0.8);

            trainXs = tf.tensor2d(trainSequences.slice(0, trainSize), [trainSize, maxLength], 'int32');
            trainYs = trainLabels.slice(0, trainSize);
            valXs = tf.tensor2d(trainSequences.slice(trainSize), [trainSequences.length - trainSize, maxLength], 'int32');
            valYs = trainLabels.slice(trainSize);
            testXs = tf.tensor2d(testSequences, [testSequences.length, maxLength], 'int32');

            // Dispose of original large tensor
            trainLabels.dispose();

            tokenizeStatus.textContent = `✅ Tokenization Complete! Vocab Size: ${vocabSize}. 
                Train Samples: ${trainXs.shape[0]}, Validation Samples: ${valXs.shape[0]}.`;
            document.getElementById('trainBtn').disabled = false;
            document.getElementById('predictBtn').disabled = false;
        }

        // --- STEPS 4 & 5: EMBEDDING LAYER SETUP & NEURAL NETWORK MODEL CONSTRUCTION ---
        function createModel() {
            const embeddingDim = parseInt(document.getElementById('embeddingDim').value);
            const maxLength = parseInt(document.getElementById('maxLength').value);
            
            // Dispose of previous model if exists
            if (model) model.dispose();

            model = tf.sequential();
            
            // 4 & 5. Embedding Layer & Model Architecture
            model.add(tf.layers.embedding({
                inputDim: vocabSize, 
                outputDim: embeddingDim, 
                inputLength: maxLength
            }));
            
            // Conv1D Layer: Feature extraction
            model.add(tf.layers.conv1d({
                filters: 128, 
                kernelSize: 5, 
                activation: 'relu'
            }));

            // Global Max Pooling: Dimensionality reduction
            model.add(tf.layers.globalMaxPool1d({}));

            // Dense Layer: Non-linear transformation
            model.add(tf.layers.dense({ units: 10, activation: 'relu' }));

            // Dropout: Regularization
            model.add(tf.layers.dropout({ rate: 0.5 }));

            // Output Layer: Softmax for binary classification (2 classes)
            model.add(tf.layers.dense({ units: 1, activation: 'sigmoid' })); // Use sigmoid for binary classification probability

            // Compilation: Adam optimizer with binary cross-entropy loss
            model.compile({
                optimizer: 'adam',
                loss: 'binaryCrossentropy',
                metrics: ['accuracy']
            });

            return model;
        }

        // --- STEP 6: MODEL TRAINING ---
        async function trainModel() {
            if (!trainXs) {
                document.getElementById('trainStatus').textContent = "Please tokenize data first.";
                return;
            }

            const trainStatus = document.getElementById('trainStatus');
            const createdModel = createModel();
            
            tfvis.show.modelSummary({ name: 'Model Summary' }, createdModel);

            trainStatus.textContent = "Training model...";
            
            const history = await createdModel.fit(trainXs, trainYs, {
                epochs: 10, // Example epochs
                batchSize: 32, // Example batch size
                validationData: [valXs, valYs],
                callbacks: tfvis.show.fitCallbacks(
                    { name: 'Training Performance' },
                    ['loss', 'val_loss', 'acc', 'val_acc'],
                    { height: 200, callbacks: ['onEpochEnd'] }
                )
            });

            trainStatus.textContent = "✅ Training Complete!";
            document.getElementById('evaluateBtn').disabled = false;
            document.getElementById('batchBtn').disabled = false;
        }

        // --- STEP 7: LIVE PREDICTION INTERFACE ---
        function livePredict() {
            if (!model) {
                document.getElementById('live-prediction-output').textContent = "Model not trained yet.";
                return;
            }

            const textInput = document.getElementById('liveTextInput').value;
            const outputDiv = document.getElementById('live-prediction-output');
            const maxLength = parseInt(document.getElementById('maxLength').value);

            if (!textInput.trim()) {
                outputDiv.textContent = "Please enter text to predict.";
                return;
            }

            tf.tidy(() => {
                // Preprocessing pipeline
                const sequence = textInput.toLowerCase().split(/\W+/)
                    .filter(w => w.length > 0)
                    .map(word => wordIndex[word] || wordIndex['<unk>']);

                // Pad/truncate
                const paddedSequence = (() => {
                    if (sequence.length > maxLength) {
                        return sequence.slice(0, maxLength);
                    } else if (sequence.length < maxLength) {
                        const padding = new Array(maxLength - sequence.length).fill(wordIndex['<pad>']);
                        return sequence.concat(padding);
                    }
                    return sequence;
                })();

                const inputTensor = tf.tensor2d([paddedSequence], [1, maxLength], 'int32');

                // Model inference
                const prediction = model.predict(inputTensor);
                const score = prediction.dataSync()[0]; // AI probability (1)
                const isAI = score > 0.5;

                const resultClass = isAI ? 'ai' : 'human';
                const resultText = isAI ? 'AI' : 'Human';
                const confidence = isAI ? score : (1 - score);

                outputDiv.className = resultClass;
                outputDiv.innerHTML = `
                    Prediction: <span style="font-weight: bold;">${resultText}</span><br>
                    Confidence: ${Math.round(confidence * 10000) / 100}%
                `;
            });
        }

        // --- STEP 8: MODEL EVALUATION & METRICS ---
        async function evaluateModel() {
            if (!model || !valXs) {
                document.getElementById('metrics-output').innerHTML = "Model not trained or validation data missing.";
                return;
            }
            
            const threshold = 0.5; // Fixed threshold for this example

            document.getElementById('metrics-output').innerHTML = "Calculating metrics...";

            tf.tidy(() => {
                const valPredictions = model.predict(valXs);
                const valLabels = valYs.dataSync();
                const predictionsArray = Array.from(valPredictions.dataSync());
                
                let TN = 0, FP = 0, FN = 0, TP = 0;

                for (let i = 0; i < valLabels.length; i++) {
                    const actual = valLabels[i];
                    const predicted = predictionsArray[i] > threshold ? 1 : 0;

                    if (actual === 0 && predicted === 0) TN++;
                    else if (actual === 0 && predicted === 1) FP++;
                    else if (actual === 1 && predicted === 0) FN++;
                    else if (actual === 1 && predicted === 1) TP++;
                }

                const accuracy = (TP + TN) / (TP + TN + FP + FN);
                const precision = TP / (TP + FP || 1e-7); // Add epsilon to prevent division by zero
                const recall = TP / (TP + FN || 1e-7);
                const f1Score = 2 * (precision * recall) / (precision + recall || 1e-7);

                const metricsHTML = `
                    <h4>Model Evaluation Metrics (Threshold: ${threshold})</h4>
                    <table>
                        <tr><th>Metric</th><th>Value</th></tr>
                        <tr><td>Accuracy</td><td>${accuracy.toFixed(4)}</td></tr>
                        <tr><td>Precision</td><td>${precision.toFixed(4)}</td></tr>
                        <tr><td>Recall</td><td>${recall.toFixed(4)}</td></tr>
                        <tr><td>F1-Score</td><td>${f1Score.toFixed(4)}</td></tr>
                    </table>
                    
                    <h4>Confusion Matrix</h4>
                    <table>
                        <tr><th></th><th>Predicted Human (0)</th><th>Predicted AI (1)</th></tr>
                        <tr><th>Actual Human (0)</th><td>TN: ${TN}</td><td>FP: ${FP}</td></tr>
                        <tr><th>Actual AI (1)</th><td>FN: ${FN}</td><td>TP: ${TP}</td></tr>
                    </table>
                `;
                document.getElementById('metrics-output').innerHTML = metricsHTML;
            });
            // Tensor disposal is handled by tf.tidy()
        }

        // --- STEP 9: BATCH PREDICTION & EXPORT ---
        function batchPredictAndExport() {
            if (!model || !testXs || testData.length === 0) {
                document.getElementById('exportStatus').textContent = "Model not trained or test data missing.";
                return;
            }

            document.getElementById('exportStatus').textContent = "Running batch prediction...";

            tf.tidy(() => {
                // Run predictions on held-out test set
                const predictions = model.predict(testXs);
                const probabilities = Array.from(predictions.dataSync());

                // Prepare CSV content
                let csvContent = "Text Snippet,Prediction Label (0=Human, 1=AI),AI Probability Score\n";

                testData.forEach((d, i) => {
                    const prob = probabilities[i];
                    const label = prob > 0.5 ? 1 : 0; // Classification label
                    
                    // Escape quotes in text snippets for CSV
                    const text = `"${d.text.replace(/"/g, '""')}"`;
                    
                    csvContent += `${text},${label},${prob.toFixed(6)}\n`;
                });

                // Create a downloadable blob
                const blob = new Blob([csvContent], { type: 'text/csv;charset=utf-8;' });
                const url = URL.createObjectURL(blob);
                const link = document.createElement("a");
                link.setAttribute("href", url);
                link.setAttribute("download", "batch_predictions.csv");
                
                document.body.appendChild(link);
                link.click();
                document.body.removeChild(link);

                document.getElementById('exportStatus').textContent = "✅ Predictions exported as batch_predictions.csv!";
            });
        }
    </script>

</body>
</html>
